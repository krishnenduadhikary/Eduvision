<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lexical Analysis - Eduvision</title>
    <link
        href="https://fonts.googleapis.com/css2?family=Nunito:wght@400;700;900&family=Roboto:wght@300;400;500;700&display=swap"
        rel="stylesheet">
    <style>
        :root {
            --bg-color: #0f172a;
            --primary-text-color: #f1f5f9;
            --secondary-text-color: #94a3b8;
            --card-bg-color: #1e293b;
            --accent-blue: #38bdf8;
            --accent-yellow: #fbbf24;
            --accent-purple: #c084fc;
            --border-color: #334155;
            --code-bg: #000000;
            --success: #22c55e;
            --error: #ef4444;
            --font-primary: 'Roboto', sans-serif;
            --font-secondary: 'Nunito', sans-serif;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: var(--font-primary);
            background-color: var(--bg-color);
            color: var(--primary-text-color);
            line-height: 1.6;
        }

        /* Logo Branding */
        .logo {
            position: fixed;
            top: 20px;
            left: 30px;
            z-index: 1000;
            font-family: var(--font-secondary);
            font-weight: 900;
            font-size: 1.5rem;
            text-decoration: none;
            display: flex;
            align-items: center;
            gap: 5px;
            background: rgba(15, 23, 42, 0.8);
            padding: 5px 15px;
            border-radius: 50px;
            backdrop-filter: blur(5px);
        }

        .logo span {
            color: white;
        }

        .logo .dot {
            color: var(--accent-yellow);
        }

        /* Header */
        header {
            height: 60vh;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            text-align: center;
            background: radial-gradient(circle at center, #1e293b 0%, #0f172a 100%);
            border-bottom: 1px solid var(--border-color);
            padding: 20px;
        }

        .hero-tag {
            color: var(--accent-blue);
            text-transform: uppercase;
            letter-spacing: 3px;
            font-weight: 700;
            margin-bottom: 10px;
        }

        h1 {
            font-family: var(--font-secondary);
            font-size: 3.5rem;
            margin-bottom: 20px;
        }

        h1 span {
            color: var(--accent-yellow);
        }

        /* Main Layout */
        main {
            max-width: 1200px;
            margin: 0 auto;
            padding: 40px 20px;
        }

        section {
            background: var(--card-bg-color);
            border-radius: 16px;
            padding: 40px;
            margin-bottom: 60px;
            border: 1px solid var(--border-color);
            transition: transform 0.3s ease;
        }

        h2 {
            font-family: var(--font-secondary);
            font-size: 2rem;
            color: var(--accent-blue);
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        h2::before {
            content: '';
            width: 4px;
            height: 30px;
            background: var(--accent-yellow);
            display: inline-block;
        }

        p {
            color: var(--secondary-text-color);
            margin-bottom: 20px;
            font-size: 1.1rem;
        }

        /* Grid Cards */
        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-top: 30px;
        }

        .card {
            background: rgba(15, 23, 42, 0.5);
            padding: 25px;
            border-radius: 12px;
            border: 1px solid var(--border-color);
        }

        .card h3 {
            color: var(--accent-yellow);
            margin-bottom: 15px;
        }

        /* Comparison Table */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: #000;
            border-radius: 8px;
            overflow: hidden;
        }

        th,
        td {
            padding: 15px;
            text-align: left;
            border-bottom: 1px solid var(--border-color);
        }

        th {
            background: var(--accent-blue);
            color: var(--bg-color);
            font-weight: 900;
        }

        /* RE to DFA Transition visual */
        .flow-container {
            display: flex;
            justify-content: space-around;
            align-items: center;
            padding: 30px;
            background: var(--bg-color);
            border-radius: 12px;
            margin: 20px 0;
        }

        .node {
            padding: 15px 25px;
            background: var(--card-bg-color);
            border: 2px solid var(--accent-blue);
            border-radius: 8px;
            text-align: center;
        }

        .arrow {
            color: var(--accent-yellow);
            font-size: 1.5rem;
            font-weight: bold;
        }

        /* Interactive Lex Tool */
        .lex-tool {
            background: var(--code-bg);
            padding: 20px;
            border-radius: 12px;
            border: 1px solid var(--accent-purple);
        }

        textarea {
            width: 100%;
            height: 120px;
            background: #111;
            color: var(--accent-blue);
            border: 1px solid var(--border-color);
            padding: 15px;
            font-family: 'Courier New', monospace;
            border-radius: 8px;
            margin-bottom: 15px;
        }

        button {
            background: var(--accent-blue);
            color: black;
            border: none;
            padding: 12px 25px;
            border-radius: 6px;
            font-weight: 700;
            cursor: pointer;
            transition: 0.3s;
        }

        button:hover {
            filter: brightness(1.2);
            transform: scale(1.05);
        }

        .token-stream {
            margin-top: 20px;
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
        }

        .token-tag {
            padding: 5px 12px;
            background: var(--border-color);
            border-radius: 4px;
            font-size: 0.85rem;
            border-left: 3px solid var(--accent-yellow);
        }

        /* Footer */
        footer {
            text-align: center;
            padding: 60px;
            border-top: 1px solid var(--border-color);
            color: var(--secondary-text-color);
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 2.2rem;
            }

            section {
                padding: 20px;
            }

            .flow-container {
                flex-direction: column;
                gap: 20px;
            }
        }
    </style>
</head>

<body>

    <a href="#" class="logo">
        <span>Edu</span><svg class="w-6 h-6" style="width:24px; color:var(--accent-yellow)" fill="none"
            stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 12a3 3 0 11-6 0 3 3 0 016 0z">
            </path>
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                d="M2.458 12C3.732 7.943 7.523 5 12 5c4.478 0 8.268 2.943 9.542 7-1.274 4.057-5.064 7-9.542 7-4.477 0-8.268-2.943-9.542-7z">
            </path>
        </svg><span>ision</span>
    </a>

    <header>
        <div class="hero-tag">MSc Computer Science Module</div>
        <h1>Lexical <span>Analysis</span></h1>
        <p style="max-width: 700px;">Explore Phase 1 of Compiler Design: Where characters become tokens and raw logic
            begins its transformation.</p>
    </header>

    <main>
        <section id="intro">
            <h2>1. Introduction & Position</h2>
            <p>The Lexical Analyzer (Scanner) is the first phase of a compiler. Its main task is to read the input
                characters of the source program, group them into lexemes, and produce as output a sequence of tokens
                for each lexeme.</p>

            <div class="flow-container">
                <div class="node">Source Code<br><small>(Char Stream)</small></div>
                <div class="arrow">→</div>
                <div class="node" style="border-color: var(--accent-yellow);">Lexical
                    Analyzer<br><strong>(Scanner)</strong></div>
                <div class="arrow">→</div>
                <div class="node">Syntax Analyzer<br><strong>(Parser)</strong></div>
            </div>
            <p><strong>Interface:</strong> The Parser usually calls the scanner using a <code>getNextToken()</code>
                command. The scanner also populates the <strong>Symbol Table</strong> with identifiers found in the
                source.</p>
        </section>

        <section id="concepts">
            <h2>2. Tokens, Lexemes, and Patterns</h2>
            <p>Distinguishing between these three is fundamental to understanding lexical analysis.</p>
            <div class="grid">
                <div class="card">
                    <h3>Token</h3>
                    <p>An abstract symbol representing a unit of grammar (e.g., <code>id</code>, <code>number</code>,
                        <code>if</code>).</p>
                </div>
                <div class="card">
                    <h3>Lexeme</h3>
                    <p>The actual sequence of characters in the source code matching a token (e.g., <code>total</code>,
                        <code>3.14</code>).</p>
                </div>
                <div class="card">
                    <h3>Pattern</h3>
                    <p>A rule describing the set of strings that can form a token (usually defined by <strong>Regular
                            Expressions</strong>).</p>
                </div>
            </div>
        </section>

        <section id="re">
            <h2>3. Regular Expressions (RE)</h2>
            <p>REs are the language of tokens. They allow us to define complex patterns using simple operators.</p>
            <ul>
                <li><strong>Union (|):</strong> <code>L | M</code> (either in L or M)</li>
                <li><strong>Concatenation:</strong> <code>LM</code> (L followed by M)</li>
                <li><strong>Kleene Closure (*):</strong> <code>L*</code> (zero or more occurrences)</li>
            </ul>
            <div style="background:#000; padding: 20px; border-radius: 8px; margin-top:20px;">
                <code style="color:var(--accent-yellow)">Example (Identifier): [a-zA-Z]([a-zA-Z0-9])*</code>
            </div>
        </section>

        <section id="automata">
            <h2>4. Finite Automata: NFA vs DFA</h2>
            <p>Automata are the mathematical "machines" used to implement the scanners.</p>
            <table>
                <thead>
                    <tr>
                        <th>Feature</th>
                        <th>NFA</th>
                        <th>DFA</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Transitions</td>
                        <td>Multiple for one input (+ ε)</td>
                        <td>Unique for one input</td>
                    </tr>
                    <tr>
                        <td>Speed</td>
                        <td>Slower (backtracking)</td>
                        <td>Faster (deterministic)</td>
                    </tr>
                    <tr>
                        <td>Space</td>
                        <td>Smaller</td>
                        <td>Larger (more states)</td>
                    </tr>
                </tbody>
            </table>
            <p>In practice, we use <strong>Thompson’s Construction</strong> to convert RE to NFA, and <strong>Subset
                    Construction</strong> to convert NFA to DFA for efficient execution.</p>
        </section>

        <section id="demo">
            <h2>5. Interactive Tokenizer Demo</h2>
            <p>Type code below to see how Eduvision's Lexical Engine processes characters into tokens in real-time.</p>
            <div class="lex-tool">
                <textarea id="userInput" placeholder="int main() { return a + 10; }"></textarea>
                <button onclick="tokenizeCode()">Process Lexemes</button>
                <div class="token-stream" id="output">
                </div>
            </div>
        </section>

        <section id="errors">
            <h2>6. Lexical Errors & Recovery</h2>
            <p>A scanner must handle strings that don't match any pattern.</p>
            <div class="grid">
                <div class="card" style="border-left: 4px solid var(--error);">
                    <h3>Panic Mode</h3>
                    <p>Delete successive characters from the input until a well-formed token is found.</p>
                </div>
                <div class="card" style="border-left: 4px solid var(--accent-yellow);">
                    <h3>Transformation</h3>
                    <p>Attempt to fix the error by replacing, inserting, or transposing a character.</p>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <p>© 2026 Eduvision Project | Designed by Krishnendu Adhikary</p>
        <p style="font-size: 0.8rem; margin-top: 10px;">Academic Reference: Aho, Sethi, Ullman (Dragon Book)</p>
    </footer>

    <script>
        function tokenizeCode() {
            const input = document.getElementById('userInput').value;
            const output = document.getElementById('output');
            output.innerHTML = '';

            // Simple Lexical Rules
            const rules = [
                { type: 'KEYWORD', regex: /\b(int|float|return|if|else|while|for)\b/g },
                { type: 'ID', regex: /\b[a-zA-Z_][a-zA-Z0-9_]*\b/g },
                { type: 'NUM', regex: /\b\d+(\.\d+)?\b/g },
                { type: 'OP', regex: /[+\-*/=<>!]+/g },
                { type: 'PUNCT', regex: /[;(){}\[\]]/g }
            ];

            // Very simplified scanner logic for demo
            let code = input;
            const tokens = [];

            // Tokenizing based on whitespace split as a rough demo
            const words = input.split(/(\s+|[;(){}\[\]]|[+\-*/=<>!]+)/);

            words.forEach(word => {
                if (!word || word.trim() === '') return;

                let matched = false;
                for (let rule of rules) {
                    if (word.match(rule.regex)) {
                        tokens.push({ type: rule.type, val: word });
                        matched = true;
                        break;
                    }
                }
                if (!matched) tokens.push({ type: 'UNKNOWN', val: word });
            });

            tokens.forEach(t => {
                const span = document.createElement('div');
                span.className = 'token-tag';
                span.innerHTML = `<strong>${t.type}</strong>: ${t.val}`;
                if (t.type === 'UNKNOWN') span.style.borderColor = 'var(--error)';
                output.appendChild(span);
            });
        }

        // Initialize with sample
        window.onload = () => {
            document.getElementById('userInput').value = "float area = 3.14 * radius * radius;";
            tokenizeCode();
        };
    </script>
</body>

</html>